#!/usr/bin/env python3

import argparse 
import os
import numpy as np
from random import shuffle
from cv2 import cv2 as cv
from torchvision.utils import make_grid
from torchvision.transforms import ToPILImage
from PIL import Image
from tqdm import tqdm
import torch
from os.path import join
from os import listdir


def parse():
    parser = argparse.ArgumentParser()
    parser.add_argument('--light', type=str, required=True)
    parser.add_argument('--ab', type=str, required=True)
    parser.add_argument('--path_out', type=str, default=None)
    return parser.parse_args()


def main(args):
    ids = ['%05d' % i for i in range(args.num_sample)]
    num_iter = int(len(ids) / args.length)

    exit()


    if args.mode == 'sequential':
        pass
    elif args.mode == 'random':
        shuffle(ids)
        if True:
            ids = ids[:100]
            ids.sort()

        if args.print_random_id:
            for id in ids:
                print(id)
    elif args.mode == 'specify':
        ids = args.target_ids
        if ids is None:
            raise Exception('No targets are specified')
        num_iter = int(len(ids) / args.length)
    else:
        raise Exception('Invalid mode')

    if not os.path.exists(args.path_out):
        os.mkdir(args.path_out)


    if len(ids) % args.length != 0:
        num_iter += 1

    if args.transpose:
        grid_row = len(args.targets)
        cap_id_dim = 2
        cap_type_dim = 1
    else:
        grid_row = args.length
        cap_id_dim = 1
        cap_type_dim = 2

    for i in tqdm(range(num_iter)):
        if args.iter_max <= i:
            break
        id_group = ids[i * args.length: (i + 1) * args.length]
        if args.transpose:
            paths = [join(target, id + '.jpg') for id in id_group
                                           for target in args.targets]
        else:
            paths = [join(target, id + '.jpg') for target in args.targets
                                           for id in id_group]

        imgs = [cv.imread(path) for path in paths]

        if args.ccrop:
            imgs = [ccrop(img) for img in imgs]
        imgs = [cv.resize(img, (args.resolution, args.resolution))
                for img in imgs]
        imgs = [np.expand_dims(img, 0) for img in imgs]
        imgs = np.vstack(imgs)
        imgs = cv2torch(imgs)
        grid = make_grid(imgs, nrow=grid_row,
                         padding=args.pad,
                         pad_value=args.pad_val)
        fontFace = cv.FONT_HERSHEY_SIMPLEX
        fontscale = 1.2 
        color = (0, 0, 0) 
        _, height, width = grid.shape

        buff_c = 0 
        if not args.no_caption_id:
            if args.transpose:
                buff_c = 200 
                length = height 
                paper = np.ones((length, buff_c, 3)) * 255
            else:
                buff_c = 80 
                length = width
                paper = np.ones((buff_c, length, 3)) * 255
            unit = int(length / len(id_group)) 

            for j in range(len(id_group)):
                if args.transpose:
                    cv.putText(paper, str(id_group[j]), (10, unit * j + 130),
                               fontFace, fontscale, color, thickness=2)
                else:
                    cv.putText(paper, str(id_group[j]), (unit * j + 50, buff_c // 2),
                               fontFace, fontscale, color, thickness=2)

            paper = paper / 255
            paper = np.flip(paper, -1).copy()
            paper = torch.Tensor(paper).permute(2,0,1)

            if args.transpose:
                grid = torch.cat([paper, grid], cap_id_dim)
            else:
                grid = torch.cat([grid, paper], cap_id_dim)

        if not args.no_caption_type:
            if args.transpose:
                buff_t = 80 
                length = width
                paper = np.ones((buff_t, length + buff_c, 3)) * 255
            else:
                buff_t = 200
                length = height
                paper = np.ones((length + buff_c, buff_t, 3)) * 255
            unit = int(length / len(args.targets)) 

            num_iter = len(args.targets)
            if args.transpose:
                for j in range(num_iter):
                    cv.putText(paper, str(args.targets[j]), (buff_c + unit * j + 50, buff_t // 2),
                               fontFace, fontscale, color, thickness=2)
            else:
                for j in range(num_iter):
                    cv.putText(paper, str(args.targets[j]), (10, unit * j + 130),
                               fontFace, fontscale, color, thickness=2)

            paper = paper / 255
            paper = np.flip(paper, -1).copy()
            paper = torch.Tensor(paper).permute(2, 0, 1)

            if args.transpose:
                grid = torch.cat([grid, paper], cap_type_dim)
            else:
                grid = torch.cat([paper, grid], cap_type_dim)

        grid = ToPILImage()(grid)
        # grid.show()
        grid.save(join(args.path_out, '%05d.jpg' % i))
        if args.only_one:
            exit()

if __name__ == '__main__':
    args = parse()
    main(args)
