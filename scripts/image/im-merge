#!/usr/bin/env python3

import argparse 
import os
from os.path import join
from os import listdir
import numpy as np
from random import shuffle
from cv2 import cv2 as cv
from torchvision.utils import make_grid
from torchvision.transforms import ToPILImage
from PIL import Image
from tqdm import tqdm
import torch
import matplotlib.pyplot as plt


def parse():
    parser = argparse.ArgumentParser()
    parser.add_argument('targets', type=str, nargs='+')
    parser.add_argument('--target_ids', type=str, nargs='+', default=None)
    parser.add_argument('--caption_id', action='store_false')
    parser.add_argument('--caption_type', action='store_false')
    parser.add_argument('--only_one', action='store_true')
    parser.add_argument('--resolution', type=int, default=256) 
    parser.add_argument('--length', type=int, default=10) 
    parser.add_argument('--path_out', type=str, default='out')
    return parser.parse_args()


def cv2torch(x):
    x = x / 255
    x = np.flip(x, -1).copy()
    x = torch.Tensor(x).permute(0, 3, 1, 2)
    return x


def main(args):

    print('targets:', args.targets)
    if len(args.targets) < 2:
        raise Exception('target must be bigger than 1')

    num_ids = len(listdir(args.targets[0]))
    print('total ids:', num_ids)

    for i in range(1, len(args.targets)):
        if num_ids != len(listdir(args.targets[i])):
            raise Exception('The number of files in each directory \
                                must be same')

    if not os.path.exists(args.path_out):
        os.mkdir(args.path_out)

    names = {}
    for t in args.targets:
        names[t] = sorted(listdir(t))
    num_iter = int(num_ids / args.length)

    for i in tqdm(range(num_iter)):
        id_from, id_start = i * args.length, (i + 1) * args.length

        paths = []
        for target in args.targets:
            ids = names[target][id_from:id_start]
            for id in ids:
                path = join(target, id)
                paths.append(path)
        
        imgs = [cv.resize(cv.imread(path), (args.resolution, args.resolution))
            for path in paths]

        imgs = [np.expand_dims(img, 0) for img in imgs]
        imgs = np.vstack(imgs)
        imgs = cv2torch(imgs)
        grid = make_grid(imgs, nrow=args.length)



        fontFace = cv.FONT_HERSHEY_SIMPLEX
        fontscale = 1.2 
        color = (0, 0, 0) 
        if args.caption_type:
            buff = 310 
            _, length, _ = grid.shape

            unit = int(length / len(args.targets)) 
            paper = np.ones((length, buff, 3)) * 255
            for j in range(len(args.targets)):
                cv.putText(paper, str(args.targets[j]), (10, unit * j + 130),
                           fontFace, fontscale, color, thickness=2)

            paper = paper / 255
            paper = np.flip(paper, -1).copy()
            paper = torch.Tensor(paper).permute(2,0,1)
            grid = torch.cat([paper, grid], 2)


        grid = ToPILImage()(grid)
        grid.save(join(args.path_out, '%05d.jpg' % i))
        if args.only_one:
            exit()


if __name__ == '__main__':
    args = parse()
    main(args)
